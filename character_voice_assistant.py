import os
import time
import tempfile
import streamlit as st
import speech_recognition as sr
import pyttsx3
import google.generativeai as genai  # Google Gemini AI API

# ‚úÖ Replace this with your Google Gemini API Key
genai.configure(api_key="AIzaSyAVADR9Ye6Q19Qztbc3kQ8kIQJvh507t2Y")  # üî¥ Replace with your actual key

# ‚úÖ Set Streamlit Page Config
st.set_page_config(page_title="AI Character Voice Assistant", page_icon="üé≠", layout="wide")

# ‚úÖ Character Definitions
CHARACTERS = {
    "karen": {
        "name": "Karen",
        "backstory": "A rude and entitled customer who always demands to speak to the manager. She is impatient, loud, and never satisfied with anything.",
        "voice_properties": {"rate": 150, "volume": 1.0},
        "emoji": "üò†"
    },
    "butler": {
        "name": "James the Butler",
        "backstory": "A sophisticated, formal British butler with impeccable manners.",
        "voice_properties": {"rate": 125, "volume": 0.8},
        "emoji": "üßê"
    },
    "comedian": {
        "name": "Chuckles",
        "backstory": "A stand-up comedian who turns everything into a joke.",
        "voice_properties": {"rate": 175, "volume": 0.9},
        "emoji": "üòÇ"
    },
    "grandma": {
        "name": "Grandma Willow",
        "backstory": "A sweet, caring grandmother who loves to give advice and tell stories.",
        "voice_properties": {"rate": 120, "volume": 0.7},
        "emoji": "üëµ"
    }
}

# ‚úÖ Initialize session state
if "character" not in st.session_state:
    st.session_state.character = "karen"
if "conversation" not in st.session_state:
    st.session_state.conversation = []
if "voice_input" not in st.session_state:
    st.session_state.voice_input = ""

# ‚úÖ Function: Convert text to speech
def text_to_speech(text, voice_properties):
    engine = pyttsx3.init()
    engine.setProperty("rate", voice_properties["rate"])
    engine.setProperty("volume", voice_properties["volume"])
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
        temp_filename = tmp_file.name
    engine.save_to_file(text, temp_filename)
    engine.runAndWait()
    with open(temp_filename, "rb") as audio_file:
        audio_bytes = audio_file.read()
    os.remove(temp_filename)
    return audio_bytes

# ‚úÖ Function: Recognize speech from microphone
def recognize_speech():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.session_state.listening = True
        time.sleep(0.2)
        audio = recognizer.listen(source, timeout=5, phrase_time_limit=10)
        st.session_state.listening = False
    try:
        return recognizer.recognize_google(audio)
    except sr.UnknownValueError:
        return "I couldn't understand what you said."
    except sr.RequestError:
        return "Speech recognition service error."

# ‚úÖ Function: Generate AI-powered responses using Google's Gemini API
def generate_response(prompt):
    character = st.session_state.character
    system_prompt = f"You are {CHARACTERS[character]['name']}. Reply in their personality style."

    try:
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content(f"{system_prompt}\nUser: {prompt}")
        return response.text.strip()
    except Exception as e:
        return f"Error: {str(e)}"

# ‚úÖ **LEFT PANEL: Character Selection**
with st.sidebar:
    st.header("üé≠ Select Your Character")
    selected_character = st.selectbox(
        "Choose a character",
        list(CHARACTERS.keys()),
        format_func=lambda x: f"{CHARACTERS[x]['emoji']} {CHARACTERS[x]['name']}"
    )
    
    # Show Character Backstory
    st.markdown(f"""
    <div style="background-color:#ffcccc; padding:10px; border-radius:10px;">
        <h3 style="color:black;">{CHARACTERS[selected_character]['emoji']} {CHARACTERS[selected_character]['name']}</h3>
        <p style="color:black;">{CHARACTERS[selected_character]['backstory']}</p>
    </div>
    """, unsafe_allow_html=True)

    if selected_character != st.session_state.character:
        st.session_state.character = selected_character
        st.session_state.conversation = []

    if st.button("üîÑ Reset Conversation"):
        st.session_state.conversation = []
        st.rerun()

# ‚úÖ **RIGHT PANEL: Conversation Area**
st.markdown("<h2 style='text-align: center;'>üí¨ Conversation</h2>", unsafe_allow_html=True)

# Display Conversation
for msg in st.session_state.conversation:
    if msg["type"] == "user":
        st.markdown(f"üßë‚Äçüíª **You:** {msg['content']}")
    else:
        st.markdown(f"{CHARACTERS[msg['character']]['emoji']} **{CHARACTERS[msg['character']]['name']}:** {msg['content']}")
        if "audio" in msg:
            st.audio(msg["audio"], format="audio/wav")

# ‚úÖ **User Input Section**
st.markdown("<h3>üéôÔ∏è Your Message</h3>", unsafe_allow_html=True)
text_input = st.text_input("Type your message here", value=st.session_state.voice_input, key="user_input")

col_mic, col_send = st.columns([1, 5])

# ‚úÖ Microphone Button
if col_mic.button("üé§ Speak"):
    try:
        voice_text = recognize_speech()
        st.session_state.voice_input = voice_text
        st.rerun()
    except Exception as e:
        st.error(f"Microphone Error: {str(e)}")

# ‚úÖ Send Button
if col_send.button("üöÄ Send") and text_input:
    st.session_state.conversation.append({"type": "user", "content": text_input})

    response = generate_response(text_input)
    audio_bytes = text_to_speech(response, CHARACTERS[st.session_state.character]["voice_properties"])

    st.session_state.conversation.append({
        "type": "assistant",
        "character": st.session_state.character,
        "content": response,
        "audio": audio_bytes
    })

    st.session_state.voice_input = ""
    st.rerun()